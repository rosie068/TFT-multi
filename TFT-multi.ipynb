{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import copy\n",
    "import math\n",
    "from omegaconf import OmegaConf,DictConfig\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import torch.nn.init as init\n",
    "\n",
    "from typing import Dict, List, Union, Callable, Optional\n",
    "from IPython.display import display\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "import itertools\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_months = 75\n",
    "future_months = 25\n",
    "\n",
    "data_dir = \"example_files\"\n",
    "\n",
    "# load static variables\n",
    "static = pd.read_csv(data_dir+\"static.csv\", index_col=0).fillna(0)\n",
    "static.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "static.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "static_numeric = static[\"PatientBMI\"].values.reshape(static.shape[0],1)\n",
    "static_categoric = static.drop([\"PatientBMI\"],axis=1).astype(int).values\n",
    "\n",
    "# load time series numeric conditionals, also known into the future\n",
    "Age = pd.read_csv(data_dir+\"age.csv\")\n",
    "Age.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "Age.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "\n",
    "# load time series categorical conditionals, not known into the future\n",
    "glasgow = pd.read_csv(data_dir+\"glasgow.csv\")\n",
    "glasgow.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "glasgow.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "glasgow[glasgow>15] = 15\n",
    "glasgow = glasgow-3 ##help out of bound embedding error in the model, so now max is 12 and min is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load features to predict, in this example there are 100 times point (75 past+25 future)\n",
    "mean_BP = pd.read_csv(data_dir+\"meanBP.csv\") #.ffill(axis=1)\n",
    "mean_BP.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "mean_BP.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "\n",
    "pulse = pd.read_csv(data_dir+\"pulse.csv\") #.ffill(axis=1)\n",
    "pulse.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "pulse.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "\n",
    "SpO2 = pd.read_csv(data_dir+\"SpO2.csv\") #.ffill(axis=1)\n",
    "SpO2.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "SpO2.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "\n",
    "Resp = pd.read_csv(data_dir+\"Resp.csv\") #.ffill(axis=1)\n",
    "Resp.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "Resp.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "\n",
    "Temp = pd.read_csv(data_dir+\"Temp.csv\") #.ffill(axis=1)\n",
    "Temp.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "Temp.set_index(\"PatientEncounterCSNID\",inplace=True)\n",
    "\n",
    "print(static_numeric.shape, static_categoric.shape, glasgow.shape, Age.shape)\n",
    "print(mean_BP.shape, pulse.shape, SpO2.shape, Resp.shape, Temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labs which are conditional time series numeric values; labs can fillna because we are not predicting it, that's fine\n",
    "labs_count = 3\n",
    "labs = np.zeros((static_numeric.shape[0],past_months,3))\n",
    "count = 0\n",
    "for measure in os.listdir(data_dir):\n",
    "    if measure[:3]==\"Lab\":\n",
    "        lab = pd.read_csv(data_dir+measure).ffill(axis=1).bfill(axis=1)\n",
    "        lab.sort_values(by='PatientEncounterCSNID', inplace=True)\n",
    "        labs[:,:,count] = lab.iloc[:,1:].values\n",
    "        count += 1\n",
    "print(labs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get masks for real recorded values vs. imputed values\n",
    "age = Age.values\n",
    "\n",
    "mean_BP_mask = mean_BP.iloc[:,2:].notnull().astype('int').values\n",
    "mean_BP_filled = mean_BP.iloc[:,2:].ffill(axis=1).values\n",
    "\n",
    "pulse_mask = pulse.notnull().astype('int').values\n",
    "pulse_filled = pulse.ffill(axis=1).bfill(axis=1).values\n",
    "\n",
    "SpO2_mask = SpO2.notnull().astype('int').values\n",
    "SpO2_filled = SpO2.ffill(axis=1).bfill(axis=1).values\n",
    "\n",
    "Resp_mask = Resp.notnull().astype('int').values\n",
    "Resp_filled = Resp.ffill(axis=1).bfill(axis=1).values\n",
    "\n",
    "Temp_mask = Temp.notnull().astype('int').values\n",
    "Temp_filled = Temp.ffill(axis=1).bfill(axis=1).values\n",
    "\n",
    "# glasgow_mask = glasgow.notnull().astype('int').values\n",
    "glasgow_filled = glasgow.ffill(axis=1).bfill(axis=1)\n",
    "glasgow_filled = glasgow_filled.fillna(12).values ##fillna with 15-3 because of cardinality\n",
    "\n",
    "print(mean_BP_mask.shape, pulse_mask.shape, SpO2_mask.shape, Resp_mask.shape, Temp_mask.shape)\n",
    "\n",
    "print(np.count_nonzero(np.isnan(mean_BP_filled)), np.count_nonzero(np.isnan(pulse_filled)), np.count_nonzero(np.isnan(SpO2_filled)),\n",
    "      np.count_nonzero(np.isnan(Resp_filled)), np.count_nonzero(np.isnan(Temp_filled)), np.count_nonzero(np.isnan(glasgow_filled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.zeros((static_numeric.shape[0],past_months+future_months,5))\n",
    "targets[...,0] = mean_BP_filled\n",
    "targets[...,1] = pulse_filled\n",
    "targets[...,2] = SpO2_filled\n",
    "targets[...,3] = Resp_filled\n",
    "targets[...,4] = Temp_filled\n",
    "\n",
    "targets_masks = np.zeros((static_numeric.shape[0],future_months,5))\n",
    "targets_masks[...,0] = mean_BP_mask[:,past_months:]\n",
    "targets_masks[...,1] = pulse_mask[:,past_months:]\n",
    "targets_masks[...,2] = SpO2_mask[:,past_months:]\n",
    "targets_masks[...,3] = Resp_mask[:,past_months:]\n",
    "targets_masks[...,4] = Temp_mask[:,past_months:]\n",
    "\n",
    "targets.shape, np.count_nonzero(np.isnan(targets)), targets_masks.shape, targets_masks.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, static_numeric, static_categoric, labs, age, g_score, target_arr, target_mask):\n",
    "        self.static_categorical = static_categoric\n",
    "        self.static_numerical = static_numeric\n",
    "        \n",
    "        cohort = age.shape[0]\n",
    "        self.historical_ts_numeric = np.concatenate((labs[:,:past_months,:],\n",
    "                                                     target_arr[:,:past_months,:],\n",
    "                                                     age[:,:past_months].reshape(cohort, past_months, 1)),\n",
    "                                                     axis=-1)\n",
    "        self.historical_ts_categorical = g_score[:,:past_months].reshape(cohort, past_months, 1)\n",
    "        self.future_ts_numeric = age[:,past_months:].reshape(cohort, future_months, 1)\n",
    "        \n",
    "        self.target = target_arr[:,past_months:]\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        static_cat = self.static_categorical[idx,...]\n",
    "        static_num = self.static_numerical[idx,...]\n",
    "        hist_ts_num = self.historical_ts_numeric[idx,...]\n",
    "        hist_ts_cat = self.historical_ts_categorical[idx,...]\n",
    "        future_ts_num = self.future_ts_numeric[idx,...]\n",
    "        target_i = self.target[idx]\n",
    "        target_mask_i = self.target_mask[idx]\n",
    "        \n",
    "        return {\n",
    "            'static_feats_categorical': torch.tensor(static_cat, dtype=torch.int32),\n",
    "            'static_feats_numeric': torch.tensor(static_num, dtype=torch.float32),\n",
    "            'historical_ts_categorical': torch.tensor(hist_ts_cat, dtype=torch.int32),\n",
    "            'historical_ts_numeric': torch.tensor(hist_ts_num, dtype=torch.float32),\n",
    "            'future_ts_numeric': torch.tensor(future_ts_num, dtype=torch.float32),\n",
    "            'target': torch.tensor(target_i, dtype=torch.float32),\n",
    "            'target_mask': torch.tensor(target_mask_i, dtype=torch.int32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_numeric = static_numeric.astype(np.float32)\n",
    "static_categoric = static_categoric.astype(int)\n",
    "labs = labs.astype(np.float32)\n",
    "age = age.astype(np.float32)\n",
    "g_score = glasgow_filled.astype(int)\n",
    "targets = targets.astype(np.float32)\n",
    "targets_masks = targets_masks.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.random.choice(age.shape[0], size=int(np.floor(age.shape[0]*0.05)), replace=False)\n",
    "train_set = np.setdiff1d(np.arange(age.shape[0]), test_set)\n",
    "print(len(train_set), len(test_set))\n",
    "\n",
    "b_size = 800\n",
    "\n",
    "train_dataset = TimeSeriesDataset(static_numeric[train_set, :], \n",
    "                                  static_categoric[train_set, :], \n",
    "                                  labs[train_set, :], \n",
    "                                  age[train_set, :], \n",
    "                                  g_score[train_set,:],\n",
    "                                  targets[train_set, :],\n",
    "                                 targets_masks[train_set,:])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "test_dataset = TimeSeriesDataset(static_numeric[test_set, :],\n",
    "                                  static_categoric[test_set, :],\n",
    "                                  labs[test_set, :],\n",
    "                                  age[test_set, :],\n",
    "                                  g_score[test_set,:],\n",
    "                                 targets[test_set, :],\n",
    "                                targets_masks[test_set, :])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first=False\n",
    "for data in train_dataloader:\n",
    "    if first == False:\n",
    "        print(data['static_feats_categorical'].shape, data['static_feats_numeric'].shape, \n",
    "              data['historical_ts_categorical'].shape, data['historical_ts_numeric'].shape, \n",
    "              data['future_ts_numeric'].shape, data['target'].shape, data['target_mask'].shape)\n",
    "        first = True\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as TFT_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueueAggregator(object):\n",
    "    def __init__(self, max_size):\n",
    "        self._queued_list = []\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def append(self, elem):\n",
    "        self._queued_list.append(elem)\n",
    "        if len(self._queued_list) > self.max_size:\n",
    "            self._queued_list.pop(0)\n",
    "\n",
    "    def get(self):\n",
    "        return self._queued_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_card = (np.zeros(static_categoric.shape[1])+2).astype(int).tolist()\n",
    "\n",
    "numeric_card = (np.zeros(1)+13).astype(int).tolist() #glasgow score\n",
    "\n",
    "data_props = {'num_historical_numeric': 28,\n",
    "              'num_historical_categorical': 1,\n",
    "              'historical_categorical_cardinalities': numeric_card,\n",
    "              'num_static_numeric': 1,\n",
    "              'num_static_categorical': 74,\n",
    "              'static_categorical_cardinalities': static_card,\n",
    "              'num_future_numeric': 1,\n",
    "              'num_feature_predicted': 5\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### hyperparameter tuning\n",
    "# hyperparams = {\n",
    "#     'batch_sizes': [400, 800, 1024, 2048],\n",
    "#     'learning_rates': [1e-3, 1e-5],\n",
    "#     'max_grad_norms': [100],\n",
    "#     'dropout': [0.1, 0.3, 0.9],\n",
    "#     'state_size': [120, 240],\n",
    "#     'lstm_layers': [2,3,4]\n",
    "#     'attension_heads': [2,4]\n",
    "# }\n",
    "\n",
    "# a = hyperparams.values()\n",
    "# combinations = list(itertools.product(*a))\n",
    "# hyperparam_tune_results = {}\n",
    "\n",
    "# for c in combinations:\n",
    "#     hyperparam_tune_results[c] = [0,0]\n",
    "    \n",
    "# hyperparam_tune_results\n",
    "# # # np.save(\"test.npy\", hyperparam_tune_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss functions\n",
    "def compute_quantile_loss_instance_wise(outputs: torch.Tensor,\n",
    "                                        targets: torch.Tensor,\n",
    "                                        masks: torch.Tensor,\n",
    "                                        desired_quantiles: torch.Tensor) -> torch.Tensor:\n",
    "    errors = targets.unsqueeze(-1) - outputs\n",
    "    # errors: [num_samples x num_horizons x num_features x num_quantiles]\n",
    "    \n",
    "    # mask to account for losses only on real values\n",
    "    for i in range(masks.shape[-1]):\n",
    "        for j in range(len(desired_quantiles)):\n",
    "            errors[...,i,j] = errors[...,i,j]*masks[...,i]\n",
    "\n",
    "    # compute the loss separately for each sample,time-step,quantile\n",
    "    losses_array = torch.max((desired_quantiles - 1) * errors, desired_quantiles * errors)\n",
    "    # losses_array: [num_samples x num_horizons x num_features x num_quantiles]\n",
    "\n",
    "    return losses_array\n",
    "\n",
    "\n",
    "def get_quantiles_loss_and_q_risk(outputs: torch.Tensor,\n",
    "                                  targets: torch.Tensor,\n",
    "                                  masks: torch.Tensor,\n",
    "                                  desired_quantiles: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
    "    outputs = outputs.reshape((outputs.shape[0], future_months, 5, 3))\n",
    "    losses_array = compute_quantile_loss_instance_wise(outputs=outputs,\n",
    "                                                       targets=targets,\n",
    "                                                       masks = masks,\n",
    "                                                       desired_quantiles=desired_quantiles)\n",
    "        \n",
    "    # sum losses over quantiles and average across time and observations\n",
    "    q_loss = (losses_array.sum(dim=-1)).sum(dim=-1).mean(dim=-1).mean()\n",
    "\n",
    "    # compute q_risk for each quantile\n",
    "    q_risk = 2 * (losses_array.sum(dim=1).sum(dim=0)) / (targets.abs().sum().unsqueeze(-1))\n",
    "    q_risk = q_risk.sum(dim=0)\n",
    "\n",
    "    return q_loss, q_risk, losses_array\n",
    "\n",
    "def process_batch(batch: Dict[str,torch.tensor],\n",
    "                  model: nn.Module,\n",
    "                  quantiles_tensor: torch.tensor,\n",
    "                  device:torch.device):\n",
    "         \n",
    "    if device.type==\"cuda\":\n",
    "        for k in list(batch.keys()):\n",
    "            batch[k] = batch[k].to(device)\n",
    "    \n",
    "    batch_outputs = model(batch)\n",
    "    labels = batch['target'] # [batch, future_months, num_feat]\n",
    "    target_masks = batch['target_mask']\n",
    "    \n",
    "    # [batch, future_months, num_feat*num_quantiles]\n",
    "    predicted_quantiles = batch_outputs['predicted_quantiles']\n",
    "    \n",
    "    q_loss, q_risk, _ = get_quantiles_loss_and_q_risk(outputs=predicted_quantiles,\n",
    "                                                      targets=labels,\n",
    "                                                      masks=target_masks,\n",
    "                                                      desired_quantiles=quantiles_tensor)\n",
    "    return q_loss, q_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_steps = past_months\n",
    "future_steps = future_months\n",
    "num_epochs = 2000\n",
    "\n",
    "# what is the running-window used by our QueueAggregator object for monitoring the training performance\n",
    "ma_queue_size = 50\n",
    "# how many evaluation rounds should we allow, without any improvement in the performance\n",
    "patience_limit = 20\n",
    "\n",
    "# a = hyperparams.values()\n",
    "# combinations = list(itertools.product(*a))\n",
    "\n",
    "# for c in combinations:\n",
    "#     print(c)\n",
    "configuration = {'optimization':\n",
    "                 {\n",
    "                     'batch_size': b_size,\n",
    "                     'learning_rate': 1e-3,\n",
    "                     'max_grad_norm': 100,\n",
    "                 }\n",
    "                 ,\n",
    "                 'model':\n",
    "                 {\n",
    "                     'dropout': 0.3,\n",
    "                     'state_size': 240,\n",
    "                     'output_quantiles': [0.1, 0.5, 0.9],\n",
    "                     'lstm_layers': 2,\n",
    "                     'attention_heads': 2\n",
    "                 },\n",
    "                 # these arguments are related to possible extensions of the model class\n",
    "                 'task_type':'regression',\n",
    "                 'target_window_start': None,\n",
    "                 'data_props': data_props\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_model = TFT_model.TemporalFusionTransformer(OmegaConf.create(configuration))\n",
    "tft_model = nn.DataParallel(tft_model, device_ids=[0,1])\n",
    "tft_model.to(device)\n",
    "print(device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=b_size, shuffle=True,num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=b_size, shuffle=True, num_workers=4)\n",
    "\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, list(tft_model.parameters())),\n",
    "                lr=configuration['optimization']['learning_rate'])\n",
    "\n",
    "# initialize the loss aggregator for running window performance estimation\n",
    "loss_aggregator = QueueAggregator(max_size=ma_queue_size)\n",
    "quantiles_tensor = torch.tensor(configuration['model']['output_quantiles']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "loss_arr_test = []\n",
    "patience = 0\n",
    "min_loss = 9999\n",
    "best_model = tft_model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_e = 0\n",
    "    loss_e_test = 0\n",
    "\n",
    "    tft_model.train()\n",
    "    for data in train_dataloader:\n",
    "        opt.zero_grad()\n",
    "                \n",
    "        loss,_ = process_batch(batch=data,\n",
    "                               model=tft_model,\n",
    "                               quantiles_tensor=quantiles_tensor,\n",
    "                               device=device)\n",
    "        loss_e += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        if configuration['optimization']['max_grad_norm'] > 0:\n",
    "            nn.utils.clip_grad_norm_(tft_model.parameters(), configuration['optimization']['max_grad_norm'])\n",
    "\n",
    "        opt.step()\n",
    "        loss_aggregator.append(loss.item())\n",
    "    loss_arr.append(loss_e)\n",
    "\n",
    "    # early stopping on performance\n",
    "    if len(loss_arr) > 1:\n",
    "            if min_loss > loss_arr[-1]: ##greater than or equal to, or set a minimum loss to compare to\n",
    "                min_loss = loss_arr[-1]\n",
    "                best_model = tft_model\n",
    "                patience = 0\n",
    "            else:\n",
    "                if patience > patience_limit:\n",
    "                    torch.save(best_model, \"TFT-multi.pt\")\n",
    "                    np.savetxt(\"TFT-multi_train_loss\",loss_arr)\n",
    "                    np.savetxt(\"TFT-multi_test_loss\",loss_arr_test)\n",
    "\n",
    "                    print(\"Patient max reached, exiting training.\")\n",
    "                    break\n",
    "                else:\n",
    "                    patience += 1\n",
    "    \n",
    "    if epoch%500 == 499:\n",
    "        torch.save(tft_model, \"TFT-multi_\"+str(epoch)+\".pt\")\n",
    "        np.savetxt(\"TFT-multi_train_loss\",loss_arr)\n",
    "        np.savetxt(\"TFT-multi_test_loss\",loss_arr_test)\n",
    "\n",
    "    ## evaluation round for test dataset\n",
    "    tft_model.eval()\n",
    "    with torch.no_grad():\n",
    "        q_loss_eval, q_risk_eval = [], []\n",
    "        \n",
    "        for test_data in test_dataloader:\n",
    "            batch_loss,batch_q_risk = process_batch(batch=test_data,\n",
    "                                                    model=tft_model,\n",
    "                                                    quantiles_tensor=quantiles_tensor,\n",
    "                                                    device=device)\n",
    "            loss_e_test += batch_loss.item()\n",
    "            q_loss_eval.append(batch_loss)\n",
    "            q_risk_eval.append(batch_q_risk)\n",
    "        \n",
    "        eval_loss = torch.stack(q_loss_eval).mean(axis=0)\n",
    "        eval_q_risk = torch.stack(q_risk_eval,axis=0).mean(axis=0)\n",
    "        loss_arr_test.append(loss_e_test)\n",
    "    \n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train Loss = {np.mean(loss_aggregator.get())}\" + \n",
    "          f\" Test q_loss = {eval_loss:.5f} , \" + \n",
    "          \" , \".join([f\"q_risk_{q:.1} = {risk:.5f}\" for q,risk in zip(quantiles_tensor,eval_q_risk)]))\n",
    "\n",
    "# hyperparam_tune_results[c] = [loss_arr[-1], loss_arr_test[-1]]\n",
    "# np.save(\"hyperparam_tune_results.npy\", hyperparam_tune_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as vis\n",
    "\n",
    "tft_model = TFT_model.TemporalFusionTransformer(OmegaConf.create(configuration))\n",
    "tft_model = torch.load(\"TFT-multi.pt\")\n",
    "\n",
    "tft_model.to(device)\n",
    "tft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams.update({'figure.autolayout': True,\n",
    "                 'figure.figsize': [10, 5],\n",
    "                 'font.size': 17})\n",
    "\n",
    "def process_test_batch(batch: Dict[str,torch.tensor],\n",
    "                  model: nn.Module,\n",
    "                  quantiles_tensor: torch.tensor,\n",
    "                  device:torch.device):\n",
    "         \n",
    "    if device.type==\"cuda\":\n",
    "        for k in list(batch.keys()):\n",
    "            batch[k] = batch[k].to(device)\n",
    "    \n",
    "    batch_outputs = model(batch)\n",
    "    labels = batch['target'] # [batch, future_months, num_feat]\n",
    "    target_masks = batch['target_mask']\n",
    "    \n",
    "    # [batch, future_months, num_feat*num_quantiles]\n",
    "    predicted_quantiles = batch_outputs['predicted_quantiles']\n",
    "        \n",
    "    q_loss, q_risk, _ = get_quantiles_loss_and_q_risk(outputs=predicted_quantiles,\n",
    "                                                      targets=labels,\n",
    "                                                      masks=target_masks,\n",
    "                                                      desired_quantiles=quantiles_tensor)\n",
    "    return q_loss, q_risk, predicted_quantiles.cpu().numpy(), labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate metric\n",
    "\n",
    "total_counter = 0\n",
    "\n",
    "individual_percent_bounded = np.zeros((5,len(test_set)))-10\n",
    "MAE = np.zeros((5,3))\n",
    "MAPE = np.zeros((5,3))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        mask = data['target_mask'] #shape 800, 25, 5\n",
    "        batch_loss,batch_q_risk,prediction,true = process_test_batch(batch=data,\n",
    "                                                                     model=tft_model,\n",
    "                                                                     quantiles_tensor=quantiles_tensor,\n",
    "                                                                     device=device)\n",
    "        #prediction.shape = 800, 25, 18, where first 3 is one measure, etc\n",
    "        #true.shape = 800, 25, 5\n",
    "        \n",
    "        for meas in range(5):\n",
    "            prediction_this_measure = prediction[...,3*meas:3*(meas+1)]\n",
    "            true_this_measure = true[...,meas]\n",
    "            mask_this_measure = mask[...,meas]\n",
    "            counter = 0\n",
    "        \n",
    "            for i in range(prediction.shape[0]):\n",
    "                x1 = prediction_this_measure[i,:,0]\n",
    "                x5 = prediction_this_measure[i,:,1]\n",
    "                x9 = prediction_this_measure[i,:,2]\n",
    "                y = true_this_measure[i,:]\n",
    "                ind_mask = mask_this_measure[i,:].cpu().numpy()\n",
    "\n",
    "                within_bound_counter = 0\n",
    "                valid_time_points = 0\n",
    "                MAE_1 = 0\n",
    "                MAE_5 = 0\n",
    "                MAE_9 = 0\n",
    "\n",
    "                MAPE_1 = 0\n",
    "                MAPE_5 = 0\n",
    "                MAPE_9 = 0\n",
    "                \n",
    "                for j in range(25):\n",
    "                    if ind_mask[j]==1 and y[j]>0:\n",
    "                        valid_time_points += 1\n",
    "\n",
    "                        MAE_1 += np.abs(x1[j]-y[j])\n",
    "                        MAE_5 += np.abs(x5[j]-y[j])\n",
    "                        MAE_9 += np.abs(x9[j]-y[j])\n",
    "\n",
    "                        MAPE_1 += np.abs((x1[j]-y[j])/y[j])\n",
    "                        MAPE_5 += np.abs((x5[j]-y[j])/y[j])\n",
    "                        MAPE_9 += np.abs((x9[j]-y[j])/y[j])\n",
    "\n",
    "                        if x1[j] <= y[j] and x9[j] >= y[j]:\n",
    "                            within_bound_counter += 1\n",
    "                \n",
    "                if valid_time_points > 0:\n",
    "                    MAE[meas, 0] += MAE_1*1.0/valid_time_points\n",
    "                    MAE[meas, 1] += MAE_5*1.0/valid_time_points\n",
    "                    MAE[meas, 2] += MAE_9*1.0/valid_time_points\n",
    "\n",
    "                    MAPE[meas, 0] += MAPE_1*1.0/valid_time_points\n",
    "                    MAPE[meas, 1] += MAPE_5*1.0/valid_time_points\n",
    "                    MAPE[meas, 2] += MAPE_9*1.0/valid_time_points\n",
    "                    \n",
    "                    individual_percent_bounded[meas, total_counter+counter] = within_bound_counter * 100.0 / valid_time_points\n",
    "                else:\n",
    "                    individual_percent_bounded[meas, total_counter+counter] = -10 #i will drop these later\n",
    "                \n",
    "                counter += 1\n",
    "        total_counter += mask.shape[0]\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame(np.transpose(individual_percent_bounded), columns=['sys_BP','dias_BP','pulse','SpO2','resp','temp'])\n",
    "tmp = tmp[~tmp.isin([-10]).any(axis=1)]\n",
    "\n",
    "for c in range(tmp.shape[1]):\n",
    "    measure = tmp.iloc[:,c]\n",
    "    measure = measure.loc[measure>=0]\n",
    "    \n",
    "    print(\"for measure \"+ tmp.columns.values[c]+\" with total count \"+str(measure.shape[0]))\n",
    "    print(\"MAE for percentiles: \", MAE[c,:]*1.0/measure.shape[0])\n",
    "    print(\"MAPE for percentiles: \", MAPE[c,:]*1.0/measure.shape[0])\n",
    "    \n",
    "    for i in range(50,110,10):\n",
    "        num = measure.loc[measure>=i].shape[0]\n",
    "        print(\"num patients with correct bound \"+str(i)+\"% of trajectory: \" + str(num)\n",
    "             + \" (\" + str(num*100.0/measure.shape[0]) +\"%)\")\n",
    "    \n",
    "    print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## sample visualization on test set\n",
    "percentile_10 = []\n",
    "percentile_50 = []\n",
    "percentile_90 = []\n",
    "num_features_predicted = 5\n",
    "\n",
    "signal_history_arr = np.zeros((len(test_set), past_months))\n",
    "true_y = np.zeros((len(test_set), future_months, 5))\n",
    "predict_y = np.zeros((len(test_set), future_months, 5, 3))\n",
    "counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        mask = data['target_mask']\n",
    "        \n",
    "        batch_loss,batch_q_risk,prediction,true = process_test_batch(batch=data,\n",
    "                                                                     model=tft_model,\n",
    "                                                                     quantiles_tensor=quantiles_tensor,\n",
    "                                                                     device=device)\n",
    "\n",
    "        \n",
    "        for meas in range(5):\n",
    "            signal_history_arr = data['historical_ts_numeric'][...,-7+meas].cpu().numpy()\n",
    "            print(\"=====================================\")\n",
    "            prediction_this_measure = prediction[...,3*meas:3*(meas+1)]\n",
    "            true_this_measure = true[...,meas]\n",
    "            mask_this_measure = mask[...,meas]\n",
    "            counter = 0\n",
    "        \n",
    "            for i in range(3):\n",
    "                vis.display_target_trajectory(signal_history=signal_history_arr,\n",
    "                                              signal_future=true_this_measure,\n",
    "                                              model_preds=prediction_this_measure,\n",
    "                                              observation_index=i,\n",
    "                                              model_quantiles=configuration['model']['output_quantiles'],\n",
    "                                              unit='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bland_altman\n",
    "def bland_altman_plot(ground_truth, predicted, predicted_upper, predicted_lower):\n",
    "    # Calculate the means and differences\n",
    "    means = (ground_truth + predicted) / 2\n",
    "    differences = predicted - ground_truth\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the differences\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "    \n",
    "    # Plot the points\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.errorbar(means, differences, yerr=[predicted - predicted_lower, predicted_upper - predicted], \n",
    "                 fmt='o', marker='.', color='blue', ecolor='green', alpha=0.5)\n",
    "    \n",
    "    # Plot the mean difference and limits of agreement\n",
    "    plt.axhline(mean_diff, color='black', linestyle='-')\n",
    "    plt.axhline(mean_diff + 1.96 * std_diff, color='black', linestyle='--')\n",
    "    plt.axhline(mean_diff - 1.96 * std_diff, color='black', linestyle='--')\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.title(f'Bland-Altman Mean BP: {mean_diff:.2f} +/- {std_diff:.2f}')\n",
    "    plt.xlabel('Ground Truth')\n",
    "    plt.ylabel('Prediction - Ground Truth')\n",
    "    \n",
    "    # Adding the legend\n",
    "    plt.legend([f'N={len(ground_truth)}'], loc='upper left')\n",
    "    \n",
    "    plt.xlim(50,118)\n",
    "    plt.ylim(-70,40)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT1 = []\n",
    "P1 = []\n",
    "U1 = []\n",
    "L1 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:        \n",
    "        meas=1\n",
    "        true_this_measure = data['target'][...,meas].cpu().numpy()\n",
    "\n",
    "        batch_loss,batch_q_risk,prediction,true = process_test_batch(batch=data,\n",
    "                                                                     model=tft_model,\n",
    "                                                                     quantiles_tensor=quantiles_tensor,\n",
    "                                                                     device=device)\n",
    "        prediction_this_measure = prediction[...,3*meas:3*(meas+1)]\n",
    "        prediction = prediction_this_measure[...,1]\n",
    "        upper = prediction_this_measure[...,2]\n",
    "        lower = prediction_this_measure[...,0]\n",
    "        \n",
    "        for i in range(mask_this_measure.shape[0]):\n",
    "            for j in range(mask_this_measure.shape[1]):\n",
    "                if mask_this_measure[i,j] == 1:\n",
    "                    GT1 = np.append(GT1, true_this_measure[i,j])\n",
    "                    P1 = np.append(P1, prediction[i,j])\n",
    "                    U1 = np.append(U1, upper[i,j])\n",
    "                    L1 = np.append(L1, lower[i,j])\n",
    "\n",
    "GT1.shape, P1.shape, U1.shape, L1.shape\n",
    "\n",
    "MGT = GT1+(GT1-GT1)/3.0\n",
    "MP = P1+(P1-P1)/3.0\n",
    "MU = U1+(U1-U1)/3.0\n",
    "ML = L1+(L1-L1)/3.0\n",
    "\n",
    "bland_altman_plot(MGT, MP, MU, ML)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftenv",
   "language": "python",
   "name": "tftenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
